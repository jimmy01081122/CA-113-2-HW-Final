優化 RISC-V 組合語言中的矩陣鏈乘法：提升快取效能之動態規劃與區塊執行指南1. 緒論與專案背景本報告旨在為計算機結構工程師提供一項關於優化 RISC-V 組合語言程式 matrix_chain_multiplication.s 的詳細指南。此專案的核心目標是透過實施動態規劃（Dynamic Programming）和區塊矩陣乘法（Tiled Matrix Multiplication）等先進技術，顯著提升矩陣鏈乘法的執行速度並根據專案特定的評分公式獲得更高分數。1.1. 矩陣鏈乘法專案概述此專案的主要目標是加速 matrix_chain_multiplication.s 函數的執行效能，其關鍵在於最小化一個特定的效能評估公式 。該公式明確指出了執行時間（Time）以及各級快取大小（L1 指令快取、L1 資料快取、L2 快取）的對數值對最終分數的影響。具體而言，效能公式為：Time×(log2​SizeL1_ICache​+log2​SizeL1_DCache​+21​log2​SizeL2_cache​) 。這意味著優化工作必須雙管齊下：不僅要減少執行週期數，還要提升快取的命中率以有效利用快取記憶體 。專案對矩陣的數量和維度設有上限：最多支援 16 個矩陣（N=16），每個矩陣的最大維度為 64（D=64）。這些限制條件對於演算法的選擇具有指導意義。例如，對於 N=16 的情況，時間複雜度為 O(N3) 的動態規劃演算法是完全可行的。同時，一個 64x64 的整數矩陣（每個整數佔 4 位元組）將佔用 64×64×4=16384 位元組，即 16KB 的儲存空間。這個大小可能會超過典型的 L1 資料快取容量，因此採用區塊化技術來改善快取局部性變得至關重要。1.2. 關鍵輸入、輸出與 RISC-V 環境目標函數 chain_matrix_multiplication 的C語言原型定義如下：int* chain_matrix_multiplication(int** matrices, int* rows, int* cols, int count); 。根據 RISC-V 呼叫慣例，其參數傳遞方式如下 ：
matrices (類型 int**，指向儲存所有矩陣位址的陣列)：存於 a0 暫存器。
rows (類型 int*，儲存每個矩陣列數的陣列)：存於 a1 暫存器。
cols (類型 int*，儲存每個矩陣行數的陣列)：存於 a2 暫存器。
count (類型 int，表示矩陣的數量)：存於 a3 暫存器。
函數的返回值 ret (類型 int*，指向計算結果矩陣的位址) 也將存於 a0 暫存器 。
所有矩陣均以列優先（row-major order）的方式儲存 。這對於在迴圈中計算記憶體位址至關重要。在 RISC-V 組合語言程式設計中，必須嚴格遵守其呼叫慣例 。這包括參數如何通過 a0-a7 暫存器傳遞，返回值如何存於 a0，以及被呼叫者（callee）和呼叫者（caller）各自負責保存哪些暫存器。特別是，若函數內部呼叫了其他函數（例如 malloc），則返回地址暫存器 ra 必須被保存。若使用了 s0-s11 等被呼叫者保存暫存器，它們的值在函數返回前也必須恢復。記憶體分配是本專案不可或缺的一環，至少需要為矩陣鏈乘法的最終結果矩陣以及可能的中間結果矩陣分配儲存空間。可以通過呼叫 malloc 函數來實現記憶體分配。呼叫 malloc 時，所需記憶體的大小（以位元組為單位）應置於 a0 暫存器；malloc 返回後，分配到的記憶體起始位址將存於 a0 。一個極其重要的細節是，malloc 函數的呼叫會覆蓋 a0, a1, a2, a3 暫存器的內容 。因此，如果在呼叫 malloc 前後需要保留這些暫存器的值，必須進行適當的保存和恢復操作。記憶體釋放則通過呼叫 free 函數完成。1.3. 優化策略：雙管齊下本報告提出的優化策略主要包含兩個方面：
動態規劃 (Dynamic Programming, DP)：用於確定一系列矩陣相乘的最佳順序（即如何加括號），以最小化總的純量乘法次數。
區塊矩陣乘法 (Tiled Matrix Multiplication)：用於優化任意兩個選定矩陣相乘時的快取使用效率，透過將大矩陣劃分為小子塊（tiles）進行處理，以增強資料局部性。
這兩種技術協同工作，以應對專案的效能目標。動態規劃首先從全域角度確定運算量最小的乘法路徑，而區塊矩陣乘法則在執行每一對矩陣乘法時，從微觀層面提升快取效能。值得注意的是，專案的效能評估公式  引入了一個微妙的平衡問題。公式中的時間項與快取大小的對數項相乘，意味著單純追求執行時間的縮短或無限制地增大快取可能並非最優策略。增大快取容量（SizeL1_ICache​, SizeL1_DCache​, SizeL2_cache​）可能會因為減少了快取未命中（cache miss）而縮短執行時間（Time），但同時也會增大公式中的對數乘數因子。反之，減小快取容量會減小乘數因子，但可能因快取未命中增多而增加執行時間。因此，最佳解是在演算法的記憶體存取模式（特別是區塊大小的選擇）與快取參數配置之間找到一個平衡點，使得總體的效能評估值最小。這要求對演算法（如區塊策略）和快取配置進行協同優化。2. 優化乘法順序：動態規劃 (DP)在矩陣鏈乘法問題中，雖然最終的乘積結果是固定的，但不同的乘法順序（即加括號的方式）會導致截然不同的計算成本（純量乘法次數）。動態規劃提供了一種系統性的方法來找出這個最優順序。2.1. 矩陣鏈乘法問題矩陣乘法滿足結合律，例如 (A×B)×C=A×(B×C)。然而，執行這些運算的成本卻可能大相徑庭 1。例如，考慮三個矩陣 M1​(10×100), M2​(100×5), M3​(5×50)。若按 ((M1​M2​)M3​) 順序計算：
M12​=M1​M2​ 需要 10×100×5=5000 次純量乘法，結果為 10×5 矩陣。
M123​=M12​M3​ 需要 10×5×50=2500 次純量乘法。
總計 5000+2500=7500 次純量乘法。
若按 (M1​(M2​M3​)) 順序計算：
M23​=M2​M3​ 需要 100×5×50=25000 次純量乘法，結果為 100×50 矩陣。
M123​=M1​M23​ 需要 10×100×50=50000 次純量乘法。
總計 25000+50000=75000 次純量乘法。
顯然，第一種順序的計算成本遠低於第二種。當乘以一個 k×m 維的矩陣 P 和一個 m×n 維的矩陣 Q 時，所需的純量乘法次數為 k×m×n 1。動態規劃的目標正是找到總純量乘法次數最少的括號方案。
2.2. 動態規劃：原理與遞迴關係動態規劃解決此問題的核心思想是最優子結構（Optimal Substructure）和重疊子問題（Overlapping Subproblems）。最優子結構指的是問題的一個最優解包含了其子問題的最優解 2。我們定義子問題 M[i,j] 為計算矩陣子鏈 Ai​Ai+1​...Aj​ 的最小純量乘法次數。遞迴關係如下 2：
若 i=j，則 M[i,i]=0 （單個矩陣無需乘法）。
若 i<j，則 M[i,j]=mini≤k<j​(M[i,k]+M[k+1,j]+pi−1​×pk​×pj​)。
這裡，k 是子鏈 Ai​...Aj​ 的分割點，即最後一次乘法發生在 (Ai​...Ak​) 和 (Ak+1​...Aj​) 之間。p 是一個維度陣列，其中矩陣 Ax​ 的維度為 px−1​×px​。
2.3. 建構維度陣列 p專案輸入為 rows (整數指標) 和 cols (整數指標) 陣列，均為0索引，其中 rows[x] 和 cols[x] 分別是第 x 個矩陣的列數和行數。動態規劃公式中使用的 p 陣列，通常與矩陣的索引方式有關。若我們將輸入的 count 個矩陣標記為 M0​,M1​,...,Mcount−1​，則：
M0​ 的維度是 rows x cols
M1​ 的維度是 rows x cols
...
Mcount−1​ 的維度是 rows[count-1] x cols[count-1]
為了適應標準的DP遞迴公式（通常假設矩陣 Ax​ 維度為 px−1​×px​ 或 px​×px+1​），我們需要構建一個包含 count + 1 個元素的 p 陣列。一種常見的構建方式（假設DP演算法使用1索引的矩陣 A1​,...,AN​，N=count）：
p = rows
p = cols (同時 cols 必須等於 rows 以保證矩陣可乘)
p = cols (同時 cols 必須等於 rows)
...
p[i] = cols[i-1] (同時 cols[i-1] 必須等於 rows[i])
...
p[count] = cols[count-1]
這樣，第 i 個輸入矩陣 (0索引 matrices[i]) 對應到DP中的 Ai+1​ (1索引)，其維度為 p[i]×p[i+1]。則DP遞迴公式 M[i,j]=mini≤k<j​(M[i,k]+M[k+1,j]+pi−1​×pk​×pj​) 中的 i,j,k 是1索引的矩陣編號。例如，若要計算 Ai​…Aj​ 的最小代價，分割點為 k，則代價為 M[i,k]+M[k+1,j] 加上 (Ai​…Ak​) 與 (Ak+1​…Aj​) 的乘法代價。(Ai​…Ak​) 的結果是一個 pi−1​×pk​ 的矩陣，(Ak+1​…Aj​) 的結果是一個 pk​×pj​ 的矩陣。因此，它們相乘的代價是 pi−1​×pk​×pj​。表1：p陣列建構範例輸入值範例 (count=3)p 陣列 (大小 count+1 = 4)說明count3三個矩陣 M0​,M1​,M2​rows10p = 10M0​ 的列數cols100p = 100M0​ 的行數 (也是 M1​ 的列數 rows)rows100(必須等於 cols)cols5p = 5M1​ 的行數 (也是 M2​ 的列數 rows)rows5(必須等於 cols)cols50p = 50M2​ 的行數矩陣維度M0​:10×100 <br> M1​:100×5 <br> M2​:5×50A1​(M0​):p0​×p1​ <br> A2​(M1​):p1​×p2​ <br> A3​(M2​):p2​×p3​正確建構 p 陣列是DP演算法成功的基礎，任何偏差都將導致錯誤的成本計算和次優的乘法順序 。2.4. DP 演算法的 RISC-V 組合語言實作實作DP演算法需要以下資料結構：
m[N][N] 表：儲存計算子鏈 Ai​...Aj​ 的最小純量乘法次數。N 等於 count。
s[N][N] 表（或稱 k_table）：儲存得到 M[i,j] 最小代價時的最佳分割點 k 2。
考慮到 N 的最大值為 16，每個表格需要 16×16 個整數。若整數為4位元組，則每個表格大小為 16×16×4=1024 位元組 (1KB)。兩個表格共 2KB。這個大小可以考慮在堆疊 (stack) 上分配，但若堆疊空間有限，或為更通用的實作，也可以使用 malloc 在堆 (heap) 上分配。採用自底向上 (Bottom-Up Tabulation) 的方法填寫 m 和 s 表 2：程式碼片段// 假設 N = count，p 陣列已根據 2.3 節建構完畢 (p...p[N])
// m[N][N] 和 s[N][N] 已分配記憶體 (例如，m 和 s 表使用1索引，範圍 1..N)

// 初始化對角線元素
// for i from 1 to N:
//   m[i][i] = 0  // 單個矩陣的乘法成本為0

// L 是子鏈的長度
// for L from 2 to N:
//   // i 是子鏈的起始矩陣索引
//   for i from 1 to N - L + 1:
//     j = i + L - 1  // j 是子鏈的結束矩陣索引
//     m[i][j] = infinity // 初始化為極大值
//     // k 是分割點，嘗試所有可能的分割
//     for k from i to j - 1:
//       // cost = m[i][k] + m[k+1][j] + p[i-1] * p[k] * p[j]
//       // 載入 m[i][k]
//       // 載入 m[k+1][j]
//       // 載入 p[i-1], p[k], p[j]
//       // 計算 temp_cost = p[i-1] * p[k]
//       // cost_mult = temp_cost * p[j]
//       // current_total_cost = m[i][k] + m[k+1][j] + cost_mult
//       
//       if current_total_cost < m[i][j]:
//         m[i][j] = current_total_cost
//         s[i][j] = k // 記錄最佳分割點
在 RISC-V 組合語言中，需要仔細管理迴圈計數器和陣列索引。巢狀迴圈的結構可參考相關的 RISC-V 程式設計範例 9。存取二維陣列 m 和 s（假設為列優先儲存）時，元素 arr[row][col] 的位址計算公式為：base_address + (row_index * num_columns + col_index) * element_size 11。2.5. 重建最佳乘法順序並執行得到 s 表後，可以透過一個遞迴函數來確定實際的乘法順序並執行它們。此函數不僅僅是「印出」括號，而是要按照 s 表指示的順序，實際呼叫矩陣乘法核心函式，並管理中間產生的矩陣。遞迴函數 Execute_Optimal_Multiplications(s_table_ptr, p_array_ptr, original_matrices_list, i, j) 的大致邏輯如下 2：程式碼片段// 輸入: s_table_ptr (指向s表), p_array_ptr (指向p維度陣列)
//       original_matrices_list (指向原始輸入矩陣指標的陣列)
//       i, j (當前要相乘的子鏈 A_i... A_j 的起始和結束索引，1-indexed)
// 返回: 指向 A_i *... * A_j 結果矩陣的指標

// function Execute_Optimal_Multiplications(s_table, p_array, matrices_list, i, j):
//   if i == j:
//     // 基本情況：子鏈只有一個矩陣，直接返回該矩陣的指標
//     // 注意：matrices_list 中的矩陣是0索引的，所以要用 i-1
//     return matrices_list[i-1] 
//   else:
//     k = s_table[i][j] // 從s表中獲取最佳分割點

//     // 遞迴計算左半部分 (A_i... A_k)
//     matrix_left_ptr = Execute_Optimal_Multiplications(s_table, p_array, matrices_list, i, k)
//     // 遞迴計算右半部分 (A_{k+1}... A_j)
//     matrix_right_ptr = Execute_Optimal_Multiplications(s_table, p_array, matrices_list, k+1, j)

//     // 確定結果矩陣的維度
//     // 結果矩陣的維度是 p[i-1] x p[j]
//     result_rows = p_array[i-1]
//     result_cols = p_array[j]
//     result_num_elements = result_rows * result_cols

//     // 為結果矩陣分配記憶體
//     // size_in_bytes = result_num_elements * sizeof(int) (e.g., 4 bytes)
//     // (記住 malloc 會修改 a0-a3，需要保存/恢復)
//     result_matrix_ptr = malloc(size_in_bytes) 

//     // 執行實際的矩陣乘法： result_matrix = matrix_left * matrix_right
//     // 這裡將呼叫區塊矩陣乘法核心 (Tiled_Matrix_Multiply)
//     // matrix_left 的維度是 p[i-1] x p[k]
//     // matrix_right 的維度是 p[k] x p[j]
//     Call_Tiled_Matrix_Multiply(matrix_left_ptr, matrix_right_ptr, result_matrix_ptr,
//                                p_array[i-1],  // rows of left
//                                p_array[k],    // cols of left / rows of right
//                                p_array[j])    // cols of right

//     // 記憶體管理：釋放不再需要的中間矩陣
//     // 如果 matrix_left_ptr 不是原始輸入矩陣 (即它是遞迴呼叫產生的中間結果)，則釋放它
//     // (需要一種機制來判斷 matrix_left_ptr 是否為中間結果)
//     if matrix_left_ptr is an intermediate result:
//       free(matrix_left_ptr)
//     // 同樣處理 matrix_right_ptr
//     if matrix_right_ptr is an intermediate result:
//       free(matrix_right_ptr)
      
//     return result_matrix_ptr
在遞迴執行乘法的過程中，一個核心的挑戰是如何有效管理中間結果矩陣的記憶體。每次由 Execute_Optimal_Multiplications 產生的新矩陣（除非是原始輸入矩陣）都需要透過 malloc 分配空間 。這些中間矩陣在作為運算元參與了更高級別的乘法後，就應當被 free 以回收記憶體，防止記憶體洩漏或耗盡。這在記憶體資源受限的模擬環境中尤為重要。關鍵在於區分原始輸入矩陣（不應在此函數中釋放）和中間矩陣（必須釋放）。若未能妥善處理，可能導致嚴重的執行期錯誤，例如記憶體耗盡或懸置指標（dangling pointer）的存取。malloc 呼叫會覆寫 a0-a3 暫存器，因此在呼叫前後，若這些暫存器中存有需要保留的值（例如迴圈計數器、基底址等），則必須先將它們保存到堆疊或其他安全位置，並在 malloc 返回後恢復。3. 高效成對乘法：區塊矩陣乘法在確定了最佳乘法順序後，接下來的挑戰是如何高效地執行每一對矩陣的乘法。標準的矩陣乘法演算法在快取利用方面表現不佳，而區塊矩陣乘法（Tiled Matrix Multiplication）正是為解決此問題而設計的。3.1. 標準矩陣乘法中的快取瓶頸標準的三重迴圈矩陣乘法（如 C[i][j] += A[i][k] * B[k][j]），在處理大型矩陣時，其資料存取模式對快取極不友好。考慮到矩陣是按列優先儲存的 ：
當存取矩陣 A 的元素 A[i][k] 時，若 k 在內層迴圈遞增，則能利用到空間局部性（同一快取行中的相鄰元素）。
然而，當存取矩陣 B 的元素 B[k][j] 時，若 k 在內層迴圈遞增而 j 固定（或在外層迴圈變化），則會導致對 B 的列式存取。由於 B 是列優先儲存，這意味著每次存取 B[k][j] 都可能跳躍到記憶體中一個較遠的位置（相隔一整列的元素），導致空間局部性差，快取行無法有效利用。
結果是，矩陣元素在被重複使用之前，往往已經被從快取中置換出去，導致大量的快取未命中和對主記憶體的緩慢存取。
3.2. 區塊化以增強資料局部性區塊矩陣乘法的核心思想是將大矩陣分割成小的子矩陣，稱為「區塊」或「瓦片」(tiles) 1。這些區塊的大小被精心選擇，以確保參與當前計算的區塊能夠完全載入並駐留在快取記憶體中（通常是 L1 資料快取）。當計算結果矩陣 C 的一個區塊 C_tile 時，例如 C_tile = C_tile + A_tile * B_tile，對應的 A_tile 和 B_tile 會被載入快取。由於這些區塊較小，它們內部的元素可以在快取中被多次重複使用，從而顯著提高時間局部性 13。這大大減少了對主記憶體的存取次數，降低了記憶體頻寬的壓力，並最終提升了執行速度。3.3. 選擇區塊大小 (TS)區塊大小 (Tile Size, TS) 的選擇是區塊矩陣乘法效能的關鍵。目標是選擇一個 TS，使得計算一個 C 區塊所需的 A 區塊、B 區塊以及 C 區塊本身能夠舒適地放入某一層級的快取中（通常是 L1 資料快取以獲得最佳效能）。假設我們計算 C_tile += A_tile * B_tile，其中每個區塊都是 TS x TS 的整數矩陣（每個整數佔4位元組）。那麼，活躍的工作集至少包含三個這樣的區塊。
三個區塊所需的記憶體總量約為 3×TS×TS×4 位元組。
這個值應小於或等於 L1 資料快取的大小。例如，如果 L1 資料快取為 4KB (4096 位元組)：
12×TS2≤4096⟹TS2≤341.33⟹TS≤341.33​≈18.47
因此，在這種情況下，TS 可以選擇為例如 16。
還需要考慮快取行的大小（Cache Line Size）。雖然專案文件未指明 ，但典型的快取行大小為 32 或 64 位元組。如果區塊的維度或起始位址能夠與快取行對齊，或者區塊大小是快取行中元素數量的倍數，可以進一步提高空間局部性並減少偽共享（false sharing，儘管在本單執行緒專案中偽共享不是主要問題，但良好的對齊仍有助於空間局部性）。
由於專案中矩陣的最大維度 D=64 ，為了簡化邊界處理，選擇的 TS 最好是 D 的因數（例如 8, 16, 32）。如果不是因數，則需要在處理矩陣邊緣的不足一個區塊大小的部分時進行特殊處理。
除了快取容量，暫存器的數量也會影響 TS 的選擇。在最內層迴圈中，如果能將一小部分區塊元素載入暫存器並重複使用，可以進一步減少對快取的存取。
表2：區塊大小選擇啟發式L1D 快取大小 (來自 gem5_args.conf)元素大小 (位元組)估算公式 (3 * TS^2 * ElemSize <= CacheSize)理論最大 TS實用 TS (建議值，考慮D=64及常見優化)4KB (4096 Bytes)4 (int)12×TS2≤4096≈188, 168KB (8192 Bytes)4 (int)12×TS2≤8192≈268, 1616KB (16384 Bytes)4 (int)12×TS2≤16384≈368, 16, 32此表提供了一個基於快取配置來初步選擇區塊大小的數據驅動方法，將理論與專案的實際參數聯繫起來 17。3.4. 區塊矩陣乘法演算法 (RISC-V 組合語言)對於 C=A×B，假設矩陣大小為 N×N，區塊大小為 TS×TS，區塊矩陣乘法通常涉及六層巢狀迴圈 16。程式碼片段// C, A, B 是矩陣的基底址
// N 是矩陣的維度 (假設 N 是 TS 的倍數以簡化)
// TS 是區塊大小

// 外層迴圈遍歷 C 矩陣的區塊
// for (ii = 0; ii < N; ii += TS) {      // C 和 A 的區塊列索引
//   for (jj = 0; jj < N; jj += TS) {  // C 和 B 的區塊行索引
//     // (可選) 初始化 C_tile。如果 C_tile 是累加結果，則 C_tile[x][y] = 0
//     // 或者，如果 C_tile 是一個暫存緩衝區，則在此處清零該緩衝區。

//     for (kk = 0; kk < N; kk += TS) {  // A 的區塊行索引 和 B 的區塊列索引
//       // 內層迴圈執行一對區塊的乘法：
//       // C_tile += 
//       //   A_tile * B_tile

//       for (i = ii; i < ii + TS; ++i) {        // 區塊內的列
//         for (j = jj; j < jj + TS; ++j) {    // 區塊內的行
//           // sum_val 用於累加 C[i][j] 的一個元素值
//           // 如果 C_tile 是暫存緩衝區，則 sum_val 從 C_tile_buffer[i-ii][j-jj] 載入
//           // 否則，如果直接累加到 C，則 sum_val = C[i][j] (如果 C 已有初始值)
//           // 或者 sum_val = 0 (如果 C 是從零開始計算)
//           // 為了優化，通常將 C[i][j] 的當前值（或0）載入一個暫存器 sum_val
//           register sum_val = C[i][j]; // 或 0, 或 C_tile_buffer[i-ii][j-jj]

//           for (k = kk; k < kk + TS; ++k) {  // 計算 C[i][j] 的內積
//             // A_ik = Load A[i][k] from memory
//             // B_kj = Load B[k][j] from memory
//             // sum_val += A_ik * B_kj
//           }
//           // Store sum_val back to C[i][j] or C_tile_buffer[i-ii][j-jj]
//           C[i][j] = sum_val; // 或 C_tile_buffer[i-ii][j-jj] = sum_val
//         }
//       }
//     }
//     // (可選) 如果 C_tile 使用了暫存緩衝區，在此將緩衝區內容寫回主記憶體的 C[ii..][jj..]
//   }
// }
專案文件  中提供的範例是一個基本的非區塊化版本，需要基於此進行擴展。在 RISC-V 中，對於列優先儲存的矩陣 A[i][k]，其位址為 base_A + (i * NumCols_A + k) * sizeof(int)。一個重要的優化考量是 C 矩陣元素的累加方式。標準的六層迴圈中，如果 C[i][j] 在最內層的 k 迴圈中頻繁地從主記憶體讀取和寫回，仍然會產生大量的記憶體流量。一個更優的策略是為當前正在計算的 C_tile 使用一個暫存緩衝區（例如，在堆疊上分配一個 TS x TS 的小陣列，或者如果 TS 非常小，甚至可以使用一組暫存器）。在 kk 迴圈（遍歷 A 的列區塊和 B 的列區塊）中，所有的中間乘積都累加到這個暫存 C_tile 緩衝區。只有當 kk 迴圈完成後，這個累加完畢的 C_tile 緩衝區的內容才一次性寫回到主記憶體中對應的 C 矩陣位置。例如，如果 TS=16，一個 C_tile 緩衝區需要 16×16×4=1KB 的空間，這對於堆疊分配是可行的。這種方法將對 C 矩陣元素的讀寫次數從 N * N * N 次（對於每個 k 都讀寫）減少到大約 N * N * (N/TS) 次（每個 C_tile 在其對應的 kk 迴圈結束後寫一次）。這顯著減少了對 C 矩陣的記憶體頻寬需求，並能更好地利用寫緩衝區（write buffer）等硬體特性。4. 在 matrix_chain_multiplication.s 中整合 DP 與區塊化將動態規劃得到的最佳乘法順序與高效的區塊化成對乘法核心結合起來，是實現最終優化目標的關鍵。4.1. 整體控制流程matrix_chain_multiplication.s 函數的整體執行流程應如下：

設定階段 (Setup):

從 a0-a3 暫存器接收輸入參數 matrices, rows, cols, count。
根據 RISC-V 呼叫慣例，保存所有需要保存的被呼叫者保存暫存器（例如 s0-s11, ra, sp）到堆疊 。
根據輸入的 rows 和 cols 陣列，建構動態規劃所需的維度陣列 p (參考第 2.3 節)。



動態規劃階段 (Dynamic Programming Phase):

分配並初始化 m 表（儲存最小乘法成本）和 s 表（儲存最佳分割點）。
執行第 2.4 節描述的動態規劃演算法，填寫 m 和 s 表。m[count-1] (或 m[count]，取決於索引方式) 將包含整個矩陣鏈的最小乘法成本，而 s 表則記錄了如何達到這個成本的分割方案。



遞迴乘法階段 (Recursive Multiplication Phase):

實作一個遞迴函數，例如 ExecuteOptimalMultiplications(s_table, p_array, original_matrices_list, i, j)。
此函數利用 s 表找到當前子鏈 Ai​...Aj​ 的最佳分割點 k=s[i][j]。
遞迴呼叫自身處理左子鏈 (Ai​...Ak​) 和右子鏈 (Ak+1​...Aj​)，分別得到結果 Matrix_Left 和 Matrix_Right。
根據 p 陣列確定這兩個子鏈相乘後結果矩陣的維度。例如，若使用0索引的矩陣 Ax​ (維度 p[x]×p[x+1])，則 Ai​...Aj​ 的結果維度為 p[i]×p[j+1]。
使用 malloc 為當前乘法結果 Result_Matrix 分配記憶體 。務必注意 malloc 對 a0-a3 的影響，在呼叫前後進行必要的保存與恢復。
呼叫區塊矩陣乘法核心函式 (參考第 3.4 節) 計算 Result_Matrix = Matrix_Left * Matrix_Right。
關鍵的記憶體管理：如果 Matrix_Left 或 Matrix_Right 是由更深層遞迴呼叫產生的中間結果（即它們不是原始輸入 matrices 陣列中的矩陣），則在它們被用於計算 Result_Matrix 之後，必須使用 free 將其釋放。
遞迴的基礎情況是當 i=j 時，直接返回 original_matrices_list[i] (或對應的1索引)。
ExecuteOptimalMultiplications(s_table, p_array, original_matrices_list, 0, count-1) (或1索引版本) 的最終返回值是指向最終乘積矩陣的指標。



返回階段 (Return):

將最終結果矩陣的位址放入 a0 暫存器。
從堆疊恢復之前保存的所有被呼叫者保存暫存器。
使用 jr ra 返回到呼叫者。


雖然 20 和 8 討論的是將DP與Strassen演算法結合，但其核心思想——即使用DP確定乘法順序，然後執行實際的（可能是優化的）矩陣乘法——與本專案是相通的。4.2. 中間矩陣管理深度剖析在遞迴乘法階段，如何準確識別並管理中間矩陣的生命週期是一個複雜但至關重要的問題。ExecuteOptimalMultiplications 函數在收到其左右子運算元 Matrix_Left 和 Matrix_Right 的指標時，需要判斷它們是原始輸入還是可以被釋放的中間結果。

識別策略：

策略1：位址範圍檢查。 如果原始輸入矩陣位於一個已知的連續記憶體區域，可以檢查指標是否落在此區域之外。但這種方法比較脆弱，依賴於 main.cpp 的分配行為。
策略2：包裹結構。 不直接傳遞 int*，而是傳遞一個指向 struct MatrixInfo 的指標，該結構包含 int* data（指向矩陣資料）、rows、cols 以及一個 is_intermediate 標誌。遞迴函數在分配新矩陣時設定此標誌。
策略3：遞迴調用者負責。 一個更為內聚的做法是，ExecuteOptimalMultiplications 函數在完成對 Matrix_Left 和 Matrix_Right 的使用（即計算出 Result_Matrix）之後，就檢查這兩個指標是否指向中間結果。如果是，則立即釋放它們。這要求函數能夠判斷一個指標的來源。最簡單的方式是，如果一個指標是由 ExecuteOptimalMultiplications 自身（或其子調用）通過 malloc 創建的，那麼它就是中間結果。



生命週期與釋放時機：一個中間矩陣從被創建（malloc）開始，其生命週期持續到它作為運算元參與了其「父級」乘法運算並產生了新的（父級）中間矩陣為止。一旦父級乘法完成，這個子級中間矩陣的資料就不再被直接需要。這意味著中間結果可以在消耗它們的乘法運算完成之後，但在當前遞迴函數返回之前被釋放。這種策略有助於最小化程式運行時的峰值記憶體使用量。例如，對於乘法序列 (A0​×A1​)×A2​：

假設 s 表指示先計算 T1​=A0​×A1​。
ExecuteOptimalMultiplications 呼叫 TiledMultiply(A_0, A_1) 產生 T_1。A_0 和 A_1 是原始輸入，不釋放。T_1 是中間結果。
接下來計算 FinalResult = T_1 \times A_2。
ExecuteOptimalMultiplications 呼叫 TiledMultiply(T_1, A_2) 產生 FinalResult。
在 FinalResult 計算完成後，T_1 的使命即告結束，應立即被 free。A_2 是原始輸入，不釋放。
FinalResult 作為整個 chain_matrix_multiplication 函數的最終返回值 ，不應在此函數內部釋放，而應由 main.cpp 中的呼叫者負責釋放。


這種精細的記憶體管理對於避免資源枯竭和保證程式穩定性至關重要。5. 效能微調：快取配置與分析除了演算法層面的優化，針對目標硬體（在此為 Gem5 模擬器）的快取參數進行調整，是提升效能的另一重要途徑。5.1. 理解可配置的快取參數 (gem5_args.conf)專案允許通過 gem5_args.conf 文件配置多個快取參數 ：
--l1i_size: L1 指令快取大小。
--l1i_assoc: L1 指令快取關聯度。
--l1d_size: L1 資料快取大小。
--l1d_assoc: L1 資料快取關聯度。
--l2_size: L2 快取大小。
--l2_assoc: L2 快取關聯度。
這些參數的影響如下：
L1 指令快取 (L1I Cache): 主要影響指令提取的效率。良好的程式碼佈局、減少不必要的跳轉、以及較小的程式碼總體積有助於提升 L1I 快取效能。矩陣演算法本身對其影響較小，更多取決於組合語言程式碼的整體結構和大小。
L1 資料快取 (L1D Cache): 對於矩陣運算至關重要，因為它直接影響矩陣元素的存取速度。區塊化技術的主要目標之一就是提升 L1D 快取的命中率。
L2 快取 (L2 Cache): 通常作為 L1 快取的後備（victim cache）。較大的 L2 快取可以捕獲那些從 L1 快取中被置換出去但仍有用的資料，從而減少對主記憶體的存取。專案文件提到 L2 快取的配置將在後續更新 。
關聯度 (Associativity): 較高的關聯度可以減少衝突未命中（conflict misses），但可能會增加快取的命中時間（hit time）或功耗。
效能評估公式  直接將這些快取的大小作為對數項納入計算，凸顯了它們的重要性。5.2. 區塊大小與快取參數的協同優化如第 1.3 節所述，效能優化需要在執行時間和快取大小的對數乘數之間取得平衡。協同優化策略建議如下：
基準設定： 從一個合理的基準快取配置開始，例如專案提供的預設值（L1I 4KB, L1D 4KB, L2 16KB）。
區塊大小選擇： 根據當前的 L1D 快取大小，參考表2的啟發式方法選擇一個初始的區塊大小 TS（例如，對於D=64，可選 TS=8 或 TS=16）。
實作與測試： 實作區塊化乘法並進行測試。使用 Gem5 的統計輸出來分析快取效能，特別是 L1D 和 L2 的未命中率。
迭代調整：

如果 L1D 未命中率過高（表示選擇的區塊工作集仍然太大或與快取映射衝突）：

可以嘗試略微增大 L1D 快取的大小（例如，從 4KB 增加到 8KB）。但需注意這會增加效能公式中的乘數因子。
或者，如果可行，可以減小區塊大小 TS。這可能會增加計算迴圈的迭代次數，但有助於區塊更好地適應 L1D 快取。


如果 L2 未命中率過高（表示 L1 的未命中未能被 L2 捕獲，導致訪問主記憶體）：

可以考慮增大 L2 快取的大小。由於效能公式中 L2 快取大小的對數項有一個 0.5 的係數，因此增加 L2 容量的「成本」（對分數的負面影響）相對低於增加 L1 容量。




持續監控： 在每次調整區塊大小或快取參數後，都要重新運行模擬，觀察總執行週期數和最終效能分數的變化。目標是找到一個使整體效能分數最小的「甜蜜點」。
5.3. 解讀 Gem5 模擬輸出Gem5 模擬會產生詳細的執行統計資訊，對於效能分析至關重要：
m5out/config.json: 包含了模擬時實際使用的快取配置等參數。
m5out/stats.txt (或專案指定的 m5out/out_exec.txt ): 包含了總執行週期數、各級快取的命中/未命中次數等詳細統計。
分析時應重點關注以下指標：
system.cpu.dcache.overall_miss_rate (L1 資料快取整體未命中率)
system.l2cache.overall_miss_rate (L2 快取整體未命中率，若 L2 已啟用並配置)
將這些統計數據與 gem5_args.conf 中的配置更改以及區塊大小的調整相關聯，以理解不同策略對快取行為的影響。
表3：快取參數 (gem5_args.conf) 調校指南參數名稱典型值範圍 (示例)對執行週期影響對效能分數乘數影響一般建議/權衡l1d_size2KB, 4KB, 8KB, 16KB, 32KB增大通常減少未命中，從而可能減少週期數增大則乘數增大關鍵參數。需與區塊大小協同優化。過小則區塊不適配，過大則乘數懲罰高。l1d_assoc1 (直接映射), 2, 4, 8增大通常減少衝突未命中，可能減少週期數無直接影響適度增加有益，但極高關聯度可能增加命中時間（模擬器可能不完全反映此細節）。通常2路或4路是較好起點。l2_size8KB, 16KB, 32KB, 64KB, 128KB增大捕獲更多L1未命中，減少訪問主記憶體，可能減少週期數增大則乘數增大 (係數0.5)由於係數較小，適當增加L2大小以改善整體未命中率通常是划算的，尤其當L1D較小時。l2_assoc1, 2, 4, 8類似L1D關聯度，減少L2內的衝突未命中無直接影響類似L1D關聯度。l1i_size2KB, 4KB, 8KB, 16KB增大通常減少指令快取未命中，對計算密集型程式影響可能較小增大則乘數增大對於本專案，指令序列相對固定，除非程式碼極度膨脹，否則影響可能不如L1D。保持合理大小即可。l1i_assoc1, 2, 4類似L1D關聯度無直接影響類似L1D關聯度。6. RISC-V 組合語言效能最佳實踐除了演算法和快取配置層面的優化，編寫高效的 RISC-V 組合語言程式碼本身也是提升效能的關鍵。6.1. 高效的暫存器分配
優先級： 將最頻繁存取的資料（例如迴圈計數器、區塊的基底址、最內層迴圈中參與運算的矩陣元素）優先分配到暫存器中。
最小化溢出： 盡量減少暫存器內容溢出 (spill) 到堆疊的情況，因為堆疊存取遠慢於暫存器存取。
遵守慣例： 根據 RISC-V 呼叫慣例正確使用呼叫者保存 (caller-saved) 和被呼叫者保存 (callee-saved) 暫存器 。這有助於模組化程式設計並避免錯誤。
6.2. 堆疊管理
高效分配： 為動態規劃的 m 和 s 表（如果選擇在堆疊上分配）、局部變數以及保存的暫存器高效地分配堆疊空間。
指標操作： 確保堆疊指標 sp 的調整正確無誤，避免堆疊溢出或資料損壞。
11 中包含了一些堆疊幀設定的範例，可供參考。
6.3. 迴圈優化
迴圈展開 (Loop Unrolling): 對於區塊矩陣乘法最內層的迴圈（通常是計算內積的 k 迴圈），進行迴圈展開可以減少迴圈控制指令的開銷，並為指令級並行 (Instruction-Level Parallelism, ILP) 提供更多機會。
強度折減 (Strength Reduction): 將計算成本高的運算替換為成本低的運算。例如，在迴圈中計算陣列位址時，如果可能，使用遞增的加法來更新位址，而不是在每次迭代中都進行完整的乘法和加法運算（儘管現代編譯器通常能自動執行此類優化）。
程式碼移動 (Code Motion): 將迴圈不變計算 (loop-invariant computations) 從迴圈內部移動到迴圈外部，避免重複計算。
6.4. 定址模式
有效地使用基底-偏移量 (base-offset) 定址模式（例如 lw reg, offset(base_reg)）來存取陣列或區塊中的元素。這通常比計算絕對位址更高效。
6.5. 分支預測
雖然分支預測更多是微架構層面的行為，但編寫結構清晰、有利於常見情況的路徑的迴圈和條件語句，有助於處理器更準確地預測分支，從而減少管線停頓。
6.6. 組合語言除錯
逐步執行與觀察： 使用模擬器或除錯器（如 RARS 9 或 Gem5 提供的檢查工具）逐步執行程式碼，觀察暫存器和記憶體狀態的變化。
增量測試： 這是組合語言程式設計（尤其是複雜演算法）的黃金法則。不要試圖一次完成所有程式碼，而是分階段實作和測試。
策略性輸出/中斷： 在程式碼的關鍵點插入系統呼叫以列印暫存器值或記憶體內容，或者使用中斷指令暫停執行以進行檢查。
一個需要注意的方面是，標準的 RISC-V 整數指令集 (RV32I/RV64I) 本身不包含專用的單指令多資料流 (SIMD) 或向量指令來直接加速矩陣運算，不像某些其他架構（例如 Arm 的 SME 或 x86 的 AMX 19）。雖然 RISC-V 存在向量擴展 ("V" extension)，但本專案文件並未指明其可用性或要求使用。專案文件  描述的矩陣乘法是基於標準的純量迴圈。相關研究如 19 討論了 RISC-V 的向量擴展（如玄鐵 MME 或自訂指令），但這些通常超出了標準大學專案的範圍，除非明確要求。因此，本專案的優化應主要集中在純量指令級的並行性、快取局部性以及演算法效率（DP、區塊化）上，而不是假設存在硬體向量支援。上述的「最佳實踐」也應基於高效的純量 RISC-V 程式碼。7. 逐步實作與驗證計畫鑑於本專案的複雜性，涉及動態規劃、區塊矩陣乘法以及底層的 RISC-V 組合語言實現和記憶體管理，強烈建議採用分階段、增量式的開發與驗證策略。試圖一次性編寫並調試所有模組將極其困難。7.1. 階段一：基本矩陣操作與 DP 邏輯驗證 (概念上等同 CPU 端邏輯)
實作 p-陣列建構： 編寫一個輔助函數或內聯邏輯來根據輸入的 rows 和 cols 陣列建構維度陣列 p。使用小規模的範例資料進行測試，驗證 p 陣列的正確性。
實作 DP m 表和 s 表計算： 編寫 RISC-V 程式碼來實現填充 m 和 s 表的巢狀迴圈邏輯。可以通過列印表格內容（使用系統呼叫）並與已知的小規模範例（例如教科書或 GeeksforGeeks 7 上的例子）進行比對，來初步調試和驗證表格內容的正確性。
實作基於 s 表的遞迴乘法 排程器 (Scheduler)： 此階段的遞迴函數尚不執行實際的矩陣乘法，而是根據 s 表的指示，確定乘法的 順序 以及中間結果矩陣的維度。它可以將這個乘法序列（例如，以括號表達式形式）或中間矩陣的維度資訊列印出來，以便與手動推演的結果進行比較。
7.2. 階段二：基本（非區塊化）成對矩陣乘法核心
實作簡單乘法核心： 在 RISC-V 組合語言中實作一個標準的三重迴圈矩陣乘法函數（類似於  中的範例）。該函數應接受兩個輸入矩陣的指標和維度，以及一個輸出矩陣的指標。
獨立測試： 使用小規模、固定大小的矩陣對此核心函式進行獨立測試。通過與手動計算結果或一個簡單的 C 語言版本進行比較，驗證其計算結果的正確性。
7.3. 階段三：整合 DP 排程器與基本乘法核心
整合呼叫： 修改階段 7.1.3 中實現的遞迴排程器函數，使其在確定每一對需要相乘的矩陣後，實際呼叫階段 7.2.1 中實現的基本乘法核心來執行運算。
記憶體管理初步實作： 在此階段引入對中間結果矩陣的 malloc 分配和 free 釋放。這是整個專案中最容易出錯的部分之一，需要極其謹慎地調試。確保中間矩陣在不再需要後被正確釋放，並且原始輸入矩陣不被錯誤釋放。
整合測試： 使用簡單的測試案例（例如，2 或 3 個小型矩陣，如專案提供的公開測試案例 00：N=3, D=3, V=10 ）對整個 chain_matrix_multiplication 函數進行測試。驗證最終計算結果的正確性。
7.4. 階段四：區塊化成對矩陣乘法核心
開發區塊化核心： 根據第 3.4 節的描述，開發區塊化矩陣乘法核心。可以從一個固定的區塊大小開始（例如，對於 D=64，TS=8 或 TS=16）。
獨立測試區塊化核心： 類似於階段 7.2.2，對區塊化乘法核心進行獨立測試。將其計算結果與基本（非區塊化）乘法核心的結果進行比較，以確保其正確性。
初步效能觀察： 如果模擬器允許，可以開始觀察區塊化核心的快取行為（例如，未命中率）。如果直接的快取統計數據難以獲取，可以先從執行週期數的變化來間接推斷其效能改進。
7.5. 階段五：完整整合與效能優化
替換核心： 在階段 7.3.1 的整合程式碼中，將對基本乘法核心的呼叫替換為對新開發的區塊化乘法核心的呼叫。
開始效能調校：

系統性地實驗不同的區塊大小 TS。
根據第 5 節的指南，調整 gem5_args.conf 中的快取參數。
使用專案提供的公開測試案例，特別是 P5（公開效能測試案例 ），來衡量當前實作相對於專案設定的基線 (baselines) 的效能 。


迭代改進： 持續迭代地調整區塊大小和快取配置，目標是最小化專案定義的效能評估公式的值。記錄每次變更及其對執行時間和預期分數的影響。
7.6. 驗證策略
利用專案工具： 在每個主要的整合階段完成後，都應使用專案提供的 testbench.py 腳本和 golden 文件來驗證輸出的正確性 。
自訂測試案例： 創建額外的小規模、邊界情況或特定模式的測試案例，用於對 DP 表的內容、中間矩陣的產生與釋放、以及區塊化邏輯的邊緣情況進行更細緻的調試和驗證。
這種增量式的開發和測試方法，雖然看起來步驟繁多，但對於處理如此複雜的底層優化任務至關重要。它將一個巨大的挑戰分解為一系列可管理、可驗證的小步驟，從而顯著提高成功實現高效能、正確解決方案的機會。每個階段的清晰產出和驗證點有助於及早發現和隔離問題，避免在後期面對一個難以調試的龐大系統。8. 結論與建議本報告詳細闡述了透過動態規劃和區塊矩陣乘法來優化 RISC-V 組合語言中矩陣鏈乘法效能的策略與實作步驟。核心目標是最小化專案定義的效能公式，該公式綜合考量了執行時間和快取大小。關鍵優化路徑總結：

動態規劃 (DP) 確定最佳乘法順序：

正確構建維度陣列 p 是 DP 演算法的基礎。
使用自底向上的表格法計算 m 表（最小成本）和 s 表（最佳分割點）。
透過遞迴函數並依賴 s 表來執行乘法，確保了以最少純量運算次數完成整個矩陣鏈的計算。



區塊矩陣乘法提升成對乘法效率：

將大型矩陣劃分為適合快取大小的區塊，顯著增強資料的時間局部性。
區塊大小 TS 的選擇需與 L1 資料快取大小緊密配合，同時考慮矩陣維度特性。
優化 C_tile 的累加方式，例如使用暫存緩衝區，可以進一步減少對主記憶體的寫入頻率。



精細的記憶體管理：

在遞迴執行乘法過程中，中間產生的矩陣需要透過 malloc 動態分配，並在不再需要後（通常是其作為運算元參與的父級乘法完成後）立即透過 free 釋放。
準確識別原始輸入矩陣與中間結果矩陣，是避免記憶體洩漏或懸置指標錯誤的關鍵。



快取參數與演算法的協同優化：

gem5_args.conf 中的快取大小和關聯度配置直接影響效能公式的乘數因子。
必須在區塊大小、演算法的記憶體存取模式與快取配置之間找到平衡，以最小化整體效能評估值。增大快取雖能減少未命中，但會增加公式的懲罰項。



RISC-V 組合語言實踐：

高效的暫存器分配、遵循呼叫慣例、優化迴圈結構（如展開）以及正確的堆疊管理，都是提升底層執行效率的重要方面。
鑑於專案未明確要求使用向量擴展，優化應聚焦於純量指令的執行效率和記憶體階層的有效利用。


建議的實施路徑：
嚴格遵循增量開發與驗證： 如第 7 節所述，將複雜任務分解為可管理、可驗證的階段。在每個階段結束時，利用提供的測試工具和自訂測試案例進行徹底驗證。
優先保證正確性： 在追求極致效能之前，首要任務是確保演算法邏輯（DP表、遞迴順序、區塊化計算）和記憶體管理的正確性。一個快速但錯誤的程式是沒有價值的。
系統性調優： 在基本功能正確後，系統地調整區塊大小和 gem5_args.conf 中的快取參數。記錄每次調整對執行週期和預期效能分數的影響，以便找到最佳配置組合。
充分利用模擬器資訊： 仔細分析 Gem5 提供的快取統計數據（如未命中率），以指導區塊大小和快取參數的調整方向。
透過上述策略的細緻實施，並結合嚴謹的測試與效能分析，工程師應能成功開發出一個高效且符合專案要求的 matrix_chain_multiplication.s 優化版本，從而在執行速度和專案分數上取得顯著提升。